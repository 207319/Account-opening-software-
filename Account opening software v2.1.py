'''æ™ºèƒ½é˜ˆå€¼ç³»ç»Ÿï¼š
è‡ªåŠ¨æ ¹æ®å…³é”®è¯é•¿åº¦è°ƒæ•´åŸºå‡†é˜ˆå€¼
æ”¯æŒæ‰‹åŠ¨è¦†ç›–é˜ˆå€¼è®¾ç½®
æ··åˆåŒ¹é…ç®—æ³•ï¼š
å­—æ®µæƒé‡ç³»ç»Ÿï¼š
å¢å¼ºç»“æœå±•ç¤ºï¼š
æ™ºèƒ½ç»“æœå¯¼å‡ºï¼š
å¼‚å¸¸å¤„ç†æœºåˆ¶
è‡ªåŠ¨è·³è¿‡æ— æ³•è§£ç çš„æ–‡ä»¶
é”™è¯¯æ–‡ä»¶ä¼šæœ‰é†’ç›®çš„âš ï¸æ ‡è¯†
ç»“æœå¯¼å‡ºè‡ªåŠ¨åˆ›å»ºç›®å½•
è‡ªåŠ¨å¤„ç†ç©ºå€¼å’Œå¼‚å¸¸æ•°æ®æ ¼å¼'''

import os
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import jaro
from datetime import datetime


class SmartTableSearcher:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.results = []
        self.supported_formats = ['.csv', '.xls', '.xlsx', '.et']
        self.field_weights = {
            'å§“å': 1.0, 'name': 1.0,
            'ç”¨æˆ·å': 0.9, 'user': 0.9,
            'å·¥å·': 0.8, 'å‘˜å·¥ç¼–å·': 0.8,
            'ç”µè¯': 0.7, 'æ‰‹æœº': 0.7,
            'éƒ¨é—¨': 0.6, 'èŒåŠ¡': 0.6
        }

    def _auto_adjust_threshold(self, keyword):
        """æ™ºèƒ½é˜ˆå€¼è°ƒèŠ‚ç³»ç»Ÿ"""
        length = len(keyword)
        if length <= 2:
            return 0.95
        elif 3 <= length <= 5:
            return 0.85
        else:
            return max(0.7, 1.0 - (length * 0.03))

    def search_in_tables(self, keyword, custom_threshold=None):
        """æ‰§è¡Œæ™ºèƒ½æœç´¢"""
        auto_threshold = self._auto_adjust_threshold(keyword)
        final_threshold = custom_threshold or auto_threshold

        self.results.clear()
        file_list = [f for f in self.data_dir.glob('*.*') if f.suffix.lower() in self.supported_formats]

        with tqdm(total=len(file_list), desc="ğŸš€ æ™ºèƒ½æ‰«æè¿›åº¦") as pbar:
            for file_path in file_list:
                try:
                    if file_path.suffix.lower() == '.csv':
                        self._process_csv(file_path, keyword, final_threshold)
                    else:
                        self._process_excel(file_path, keyword, final_threshold)
                except Exception as e:
                    print(f"\nâš ï¸ æ–‡ä»¶è¯»å–å¼‚å¸¸: {file_path.name} - {str(e)}")
                finally:
                    pbar.update(1)

        # æ™ºèƒ½ç»“æœæ’åº
        # ä¿®æ­£åçš„æ™ºèƒ½ç»“æœæ’åºéƒ¨åˆ†
        self.results.sort(
            key=lambda x: -float(x['similarity'].strip('%')),
            reverse=False
        )
        return self.results

    def _process_csv(self, file_path, keyword, threshold):
        """å¤„ç†CSVæ–‡ä»¶ï¼ˆè‡ªåŠ¨æ£€æµ‹ç¼–ç ï¼‰"""
        encodings = ['utf-8', 'gbk', 'gb18030', 'big5']
        for enc in encodings:
            try:
                df = pd.read_csv(file_path, dtype=str, encoding=enc)
                df.fillna('', inplace=True)
                self._analyze_dataframe(df, keyword, file_path.name, "CSV", threshold)
                return
            except (UnicodeDecodeError, pd.errors.ParserError):
                continue
        print(f"\nâŒ æ— æ³•è§£ç æ–‡ä»¶: {file_path.name}")

    def _process_excel(self, file_path, keyword, threshold):
        """å¤„ç†Excel/WPSæ–‡ä»¶"""
        try:
            xls = pd.ExcelFile(file_path)
            for sheet_name in xls.sheet_names:
                df = pd.read_excel(xls, sheet_name=sheet_name, dtype=str)
                df.fillna('', inplace=True)
                self._analyze_dataframe(df, keyword, file_path.name, sheet_name, threshold)
        except Exception as e:
            print(f"\nâŒ Excelè¯»å–å¤±è´¥: {str(e)}")

    def _analyze_dataframe(self, df, keyword, filename, sheetname, threshold):
        """æ‰§è¡Œæ™ºèƒ½å­—æ®µåˆ†æ"""
        for _, row in df.iterrows():
            best_match = {
                'similarity': 0,
                'field': None,
                'value': ''
            }

            for col_name, cell_value in row.items():
                clean_value = str(cell_value).strip()
                if not clean_value:
                    continue

                # ä½¿ç”¨Jaro-Winklerç®—æ³•è®¡ç®—ç›¸ä¼¼åº¦
                similarity = jaro.jaro_winkler_metric(
                    keyword.lower(),
                    clean_value.lower()
                )

                # åº”ç”¨å­—æ®µæƒé‡åŠ æˆ
                weight = self.field_weights.get(col_name.strip(), 0.5)
                similarity *= (1 + weight * 0.2)

                if similarity > best_match['similarity']:
                    best_match.update({
                        'similarity': similarity,
                        'field': col_name,
                        'value': clean_value
                    })

            if best_match['similarity'] >= threshold:
                self._record_match(
                    row, filename, sheetname,
                    best_match['similarity'], best_match['field']
                )

    def _record_match(self, row, filename, sheetname, similarity, match_field):
        """è®°å½•åŒ¹é…ç»“æœ"""
        record = {
            'file': filename,
            'sheet': sheetname,
            'similarity': f"{similarity:.1%}",
            'match_field': match_field,
            'data': {k: v for k, v in row.items() if pd.notna(v)},
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        self.results.append(record)

    def export_results(self, format_type='csv', output_dir='results'):
        """å¯¼å‡ºæœç´¢ç»“æœ"""
        if not self.results:
            print("ğŸŸ¡ æ²¡æœ‰å¯å¯¼å‡ºçš„ç»“æœ")
            return

        df = pd.json_normalize(self.results, sep='|')
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"search_results_{timestamp}"

        try:
            if format_type == 'csv':
                full_path = output_path / f"{filename}.csv"
                df.to_csv(full_path, index=False, encoding='utf_8_sig')
            elif format_type == 'excel':
                full_path = output_path / f"{filename}.xlsx"
                df.to_excel(full_path, index=False)
            else:
                print("ğŸ”´ ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼")
                return

            print(f"\nâœ… æˆåŠŸå¯¼å‡º {len(self.results)} æ¡ç»“æœåˆ°: {full_path}")
        except Exception as e:
            print(f"\nğŸ”´ å¯¼å‡ºå¤±è´¥: {str(e)}")


def main():
    print("=" * 50)
    print("æ™ºèƒ½è¡¨æ ¼æ£€ç´¢ç³»ç»Ÿ v2.1")
    print("=" * 50)

    DATA_DIR = input("è¯·è¾“å…¥æ•°æ®ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤./dataï¼‰: ").strip() or "./data"
    data_path = Path(DATA_DIR)

    if not data_path.exists():
        print(f"\nğŸ”´ é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨ {data_path}")
        return

    searcher = SmartTableSearcher(data_path)

    while True:
        keyword = input("\nğŸ” è¯·è¾“å…¥æ£€ç´¢å…³é”®è¯ï¼ˆqé€€å‡ºï¼‰: ").strip()
        if keyword.lower() == 'q':
            break

        # è·å–é˜ˆå€¼è®¾ç½®
        auto_threshold = searcher._auto_adjust_threshold(keyword)
        threshold_input = input(
            f"ğŸ“Š æ¨èé˜ˆå€¼ {auto_threshold:.2f}ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨æ¨èå€¼æˆ–è¾“å…¥è‡ªå®šä¹‰å€¼ 0.1-1.0ï¼‰: "
        ).strip()

        try:
            threshold = float(threshold_input) if threshold_input else auto_threshold
            threshold = max(0.1, min(1.0, threshold))
        except ValueError:
            print("âš ï¸ è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨æ¨èé˜ˆå€¼")
            threshold = auto_threshold

        print(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨é˜ˆå€¼ {threshold:.2f} è¿›è¡Œæœç´¢...")
        results = searcher.search_in_tables(keyword, threshold)

        if not results:
            print("\nğŸ” æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")
            continue

        # æ˜¾ç¤ºå‰5æ¡ç»“æœ
        print(f"\nğŸ‰ æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å½•ï¼ˆæ˜¾ç¤ºå‰5æ¡ï¼‰:")
        for idx, record in enumerate(results[:5], 1):
            print(f"\nã€ç»“æœ{idx}ã€‘")
            print(f"ğŸ“ æ–‡ä»¶: {record['file']}")
            print(f"ğŸ“‘ å·¥ä½œè¡¨: {record['sheet']}")
            print(f"ğŸ“ˆ åŒ¹é…åº¦: {record['similarity']}")
            print(f"ğŸ”– åŒ¹é…å­—æ®µ: {record['match_field']}")
            print("ğŸ” è¯¦ç»†ä¿¡æ¯:")
            for k, v in record['data'].items():
                print(f"  {k}: {v}")

        # å¯¼å‡ºåŠŸèƒ½
        if input("\nğŸ’¾ æ˜¯å¦å¯¼å‡ºå…¨éƒ¨ç»“æœï¼Ÿ(y/n): ").lower() == 'y':
            fmt = input("é€‰æ‹©å¯¼å‡ºæ ¼å¼ (csv/excel): ").lower().strip()
            if fmt in ('csv', 'excel'):
                searcher.export_results(fmt)
            else:
                print("âš ï¸ æ— æ•ˆæ ¼å¼ï¼Œå–æ¶ˆå¯¼å‡º")


if __name__ == "__main__":
    main()